{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Aggregated Imputed Values (LNN-LSTM Aggregation)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the imputed results from LNN and LSTM models\n",
    "lnn_results_path = r\"D:\\Reproducing the values\\MR_at_test\\Datasets\\MR_40\\For 505 lstm again run\\505_LNN_Seoul_40.csv\"\n",
    "lstm_results_path = r\"D:\\Reproducing the values\\MR_at_test\\Datasets\\MR_40\\For 505 lstm again run\\505_b1_mcar_40_imp.csv\"\n",
    "\n",
    "lnn_data = pd.read_csv(lnn_results_path)\n",
    "lstm_data = pd.read_csv(lstm_results_path)\n",
    "\n",
    "# Convert the 'datetime' feature to datetime object with the correct format\n",
    "lnn_data['datetime'] = pd.to_datetime(lnn_data['datetime'], format='%d/%m/%Y %H:%M')\n",
    "lstm_data['datetime'] = pd.to_datetime(lstm_data['datetime'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "# Ensure the data is sorted by datetime\n",
    "lnn_data = lnn_data.sort_values(by='datetime')\n",
    "lstm_data = lstm_data.sort_values(by='datetime')\n",
    "\n",
    "# Check if both dataframes have the same datetime values\n",
    "assert np.array_equal(lnn_data['datetime'], lstm_data['datetime']), \"Datetime values do not match.\"\n",
    "\n",
    "# Extract the imputed values and true values\n",
    "ytrue = lnn_data['ytrue']\n",
    "lnn_imputed = lnn_data['505_LNN_Seoul_40']\n",
    "lstm_imputed = lstm_data['505_LSTM_Seoul_40']\n",
    "\n",
    "# Add the LSTM imputed values to the LNN dataframe for consistency\n",
    "lnn_data['505_LSTM_Seoul_40'] = lstm_imputed\n",
    "\n",
    "# Insert the rmse scores computed from LNN and LSTM test data i.e. rmse = np.sqrt(mean_squared_error(y_test_inverse, test_predictions_inverse[:, 0]))\n",
    "rmse_lnn= 0.23902789713979594\n",
    "rmse_lstm= 1.964455733\n",
    "\n",
    "# Calculate the weights based on RMSE scores\n",
    "weight_lnn = (1 / rmse_lnn) / ((1 / rmse_lnn) + (1 / rmse_lstm))\n",
    "weight_lstm = (1 / rmse_lstm) / ((1 / rmse_lnn) + (1 / rmse_lstm))\n",
    "\n",
    "total_weight = weight_lnn + weight_lstm\n",
    "\n",
    "weight_lnn /= total_weight\n",
    "weight_lstm /= total_weight\n",
    "\n",
    "# Compute the aggregated imputed values\n",
    "aggregated_imputed = weight_lnn * lnn_imputed + weight_lstm * lstm_imputed\n",
    "\n",
    "# Add the aggregated imputed values to the dataframe\n",
    "lnn_data['505_Aggregated_40'] = aggregated_imputed\n",
    "\n",
    "# Calculate RMSE for aggregated imputed values\n",
    "rmse_aggregated_imputed = np.sqrt(mean_squared_error(ytrue.dropna(), aggregated_imputed[ytrue.dropna().index]))\n",
    "\n",
    "# Calculate correlations\n",
    "corr_lnn = ytrue.corr(lnn_imputed)\n",
    "corr_lstm = ytrue.corr(lstm_imputed)\n",
    "corr_aggregated = ytrue.corr(aggregated_imputed)\n",
    "\n",
    "# Calculate percentage improvement\n",
    "improvement_lnn = ((rmse_lnn - rmse_aggregated_imputed) / rmse_lnn) * 100\n",
    "improvement_lstm = ((rmse_lstm - rmse_aggregated_imputed) / rmse_lstm) * 100\n",
    "\n",
    "# Print RMSE, correlation values, and improvement percentages\n",
    "print(f'RMSE (LNN Imputed): {rmse_lnn}')\n",
    "print(f'RMSE (LSTM Imputed): {rmse_lstm}')\n",
    "print(f'RMSE (Aggregated Imputed): {rmse_aggregated_imputed}')\n",
    "print(f'Correlation (LNN Imputed): {corr_lnn}')\n",
    "print(f'Correlation (LSTM Imputed): {corr_lstm}')\n",
    "print(f'Correlation (LSTM Imputed): {corr_lstm}')\n",
    "print(f'Correlation (Aggregated Imputed): {corr_aggregated}')\n",
    "print(f'Percentage Improvement over LNN: {improvement_lnn:.4f}%')\n",
    "print(f'Percentage Improvement over LSTM: {improvement_lstm:.4f}%')\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "output_path = r\"D:\\Reproducing the values\\MR_at_test\\Datasets\\MR_40\\505_c1_Aggregated_40.csv\"\n",
    "lnn_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Aggregated imputed values saved to {output_path}\")\n",
    "\n",
    "# Plot correlations - Improved version\n",
    "\n",
    "#corr_matrix = lnn_data[['ytrue', '505_LNN_Seoul_30', '505_LSTM_Seoul_30', '505_Aggregated_30']].corr()\n",
    "#print(corr_matrix)\n",
    "\n",
    "# Plot comparison of imputed values - Improved version\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(ytrue, label='True Values', color='black', linestyle='--', linewidth=4)\n",
    "plt.plot(lnn_imputed, label='LNN Imputed', alpha=0.7, linewidth=3, color='blue', linestyle='dashed')\n",
    "plt.plot(lstm_imputed, label='LSTM Imputed', alpha=0.7, linewidth=3, color='orange')\n",
    "plt.plot(aggregated_imputed, label='Aggregated Imputed', alpha=0.7, linewidth=3, color='red', linestyle='dotted')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Comparison of Imputed Values')\n",
    "comparison_plot_path = r\"D:\\Reproducing the values\\MR_at_test\\Datasets\\MR_40\\505_c1_Aggregated_40a.png\"\n",
    "plt.savefig(comparison_plot_path)\n",
    "plt.show()\n",
    "\n",
    "# Print the weights and a few samples of the aggregated results for verification\n",
    "print(f\"Weight for LNN: {weight_lnn:.4f}\")\n",
    "print(f\"Weight for LSTM: {weight_lstm:.4f}\")\n",
    "print(lnn_data[['datetime', 'ytrue', '505_LNN_Seoul_40', '505_LSTM_Seoul_40', '505_Aggregated_40']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
